{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.0 Introdução**\n",
    "\n",
    "Código com finalidade de realizar a modelagem Cartola FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install catboost\n",
    "#%pip install shap\n",
    "#%pip install scikit-learn\n",
    "#%pip install tensorflow\n",
    "#%pip install xgboost\n",
    "#%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tratamento de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#ignorar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#modelagem\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "#shap\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "\n",
    "#grafico\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "3.0 Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregar dados\n",
    "df = (pd\n",
    ".read_csv(\"C:/Users/eduar/OneDrive/Área de Trabalho/Python/cartola_fc/gold/bases/base_final.csv\")\n",
    ")\n",
    "\n",
    "#remover colunas\n",
    "df = df.drop(columns=['entrou_em_campo', 'adv','estadio']) \n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodada_avaliada = 30\n",
    "\n",
    "#treino\n",
    "df_train = df.copy()\n",
    "df_train =  df_train[df_train['rodada'] <= (rodada_avaliada-1)] #rodadas antes\n",
    "\n",
    "df_train =  df_train[df_train['pontuacao'] <= 22] #outliers\n",
    "df_train =  df_train[df_train['pontuacao'] <= df_train['jogadores_proAvgpontuacao']*3.5 ] #outliers\n",
    "df_train =  df_train[df_train['pontuacao'] >= (df_train['jogadores_proAvgpontuacao']-15) ] #outliers\n",
    "\n",
    "\n",
    "X_train = df_train.drop(columns=['pontuacao','rodada','nome_jogador','equipe','id_jogador']) \n",
    "y_train = df_train['pontuacao']\n",
    "\n",
    "#teste\n",
    "df_test = df.copy()\n",
    "df_test =  df_test[df_test['rodada'] == rodada_avaliada]\n",
    "\n",
    "X_test = df_test.drop(columns=['pontuacao','rodada','nome_jogador','equipe','id_jogador']) \n",
    "y_test = df_test['pontuacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[df_train['rodada'] == 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Estatística Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pontuacao'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule o desvio padrão e média para cada jogador\n",
    "print((df.groupby('id_jogador')['pontuacao'].std()).mean())\n",
    "print((df.groupby('id_jogador')['pontuacao'].mean()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um gráfico de distribuição usando Seaborn\n",
    "sns.histplot(df['pontuacao'], kde=True, color='blue')\n",
    "\n",
    "# Adicione rótulos e título ao gráfico\n",
    "plt.xlabel('Pontuação')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Distribuição da Pontuação')\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.0 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_var = ['posicao']\n",
    "\n",
    "#Crie o modelo CatBoost com os parâmetros desejados, incluindo 'data_resposta' como categórica\n",
    "model = CatBoostRegressor(iterations=200,\n",
    "                          depth=8,\n",
    "                          verbose=False,\n",
    "                          cat_features=categorical_var\n",
    "                          )\n",
    "\n",
    "# Treine o modelo no conjunto de treinamento\n",
    "model.fit(X_train, y_train,\n",
    "          early_stopping_rounds=5\n",
    "          )  #Aplica early stopping se o desempenho no conjunto de validação deixar de melhorar\n",
    "\n",
    "#score de treinamento\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# Avalie o modelo no conjunto de teste (ou validação)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = df_test.drop(columns=['pontuacao','rodada','nome_jogador','equipe','id_jogador']) \n",
    "\n",
    "# Avalie o modelo no conjunto de teste (ou validação)\n",
    "y_pred = model.predict(X_final)\n",
    "\n",
    "#Adicionar uma coluna 'predicao' ao DataFrame com as previsões do modelo para os dados de treinamento\n",
    "df_test['predicao'] = y_pred.round(2)\n",
    "\n",
    "#Crie um objeto explainer SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "#Calcule os valores SHAP para um conjunto de dados de exemplo\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "#Crie um gráfico de resumo SHAP\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['nome_jogador','equipe','posicao','pontuacao','predicao','jogadores_proAvgpontuacao']]\n",
    "display(df_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar dado\n",
    "df_test.to_csv('previsao_geral.csv', index=False,mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# # Supondo que 'posicoes' seja a coluna categórica que você deseja transformar\n",
    "# X_train_dummy = pd.get_dummies(X_train, columns=['posicao'], prefix='posicao', drop_first=True)\n",
    "# X_test_dummy = pd.get_dummies(X_test, columns=['posicao'], prefix='posicao', drop_first=True)\n",
    "\n",
    "# # Normalizar os dados usando StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_dummy)\n",
    "# X_test_scaled = scaler.transform(X_test_dummy)\n",
    "\n",
    "# # Definir a arquitetura da rede neural\n",
    "# model_nn = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001), input_shape=(X_train_dummy.shape[1],)),\n",
    "#     tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "#     tf.keras.layers.Dense(1)  # Camada de saída para tarefas de regressão\n",
    "# ])\n",
    "\n",
    "# # Compilar o modelo\n",
    "# model_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# # Treinar o modelo\n",
    "# model_nn.fit(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.1, verbose=2)\n",
    "\n",
    "# # Avaliar o modelo no conjunto de teste\n",
    "# y_pred_nn = model_nn.predict(X_test_scaled)\n",
    "\n",
    "# # Avaliar o desempenho do modelo de rede neural\n",
    "# mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "# r2_nn = r2_score(y_test, y_pred_nn)\n",
    "# mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "\n",
    "# print(\"Mean Absolute Error (MAE) - Rede Neural:\", mae_nn)\n",
    "# print(f\"Mean Squared Error (MSE) - Rede Neural: {mse_nn}\")\n",
    "# print(f\"R-squared (R2) - Rede Neural: {r2_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# # Supondo que 'posicao' seja a coluna categórica que você deseja transformar\n",
    "# X_train_dummy = pd.get_dummies(X_train, columns=['posicao'], prefix='posicao', drop_first=True)\n",
    "# X_test_dummy = pd.get_dummies(X_test, columns=['posicao'], prefix='posicao', drop_first=True)\n",
    "\n",
    "# # Criar um objeto DMatrix para otimizar o desempenho do XGBoost\n",
    "# dtrain = xgb.DMatrix(X_train_dummy, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test_dummy, label=y_test)\n",
    "\n",
    "# # Definir os parâmetros do modelo\n",
    "# params = {\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'max_depth': 6,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'n_estimators': 100\n",
    "# }\n",
    "\n",
    "# # Treinar o modelo\n",
    "# model_xgb = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# # Fazer previsões no conjunto de teste\n",
    "# y_pred_xgb = model_xgb.predict(dtest)\n",
    "\n",
    "# # Avaliar o desempenho do modelo XGBoost\n",
    "# mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "# r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "# mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# print(\"Mean Absolute Error (MAE) - XGBoost:\", mae_xgb)\n",
    "# print(f\"Mean Squared Error (MSE) - XGBoost: {mse_xgb}\")\n",
    "# print(f\"R-squared (R2) - XGBoost: {r2_xgb}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
